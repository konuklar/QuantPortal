# =============================================================
# üèõÔ∏è Institutional Apollo / ENIGMA ‚Äì Quant Terminal v6.0
# Professional Portfolio Optimization & Global Multi-Asset Edition
# Enhanced Version with 3D Visualization, Advanced Risk Metrics
# =============================================================

import os
import warnings
import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from scipy import stats, optimize, spatial
from scipy.stats import norm, t, skew, kurtosis
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union, Any
import json
import concurrent.futures
from functools import lru_cache, wraps
import traceback
import time
import hashlib
import inspect
from pathlib import Path
import pickle
import tempfile
import sys
import io
import base64
import math
from itertools import combinations
from dataclasses import dataclass, asdict
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Try to import quantstats for enhanced analytics
try:
    import quantstats as qs
    QUANTSTATS_AVAILABLE = True
    # Configure quantstats
    qs.extend_pandas()
except ImportError:
    QUANTSTATS_AVAILABLE = False
    st.warning("‚ö†Ô∏è quantstats not installed. Some advanced metrics will be limited. Install with: pip install quantstats")

# Import PyPortfolioOpt with all required components
try:
    from pypfopt import expected_returns, risk_models, objective_functions, black_litterman, hierarchical_portfolio
    from pypfopt.efficient_frontier import EfficientFrontier, EfficientSemivariance, EfficientCVaR
    from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices
    from pypfopt.objective_functions import L2_reg, transaction_cost
    from pypfopt.cla import CLA
    from pypfopt.hierarchical_portfolio import HRPOpt
    from pypfopt.risk_models import CovarianceShrinkage
    PYPFOPT_AVAILABLE = True
except ImportError as e:
    PYPFOPT_AVAILABLE = False
    st.warning(f"‚ö†Ô∏è PyPortfolioOpt not installed or has import errors: {str(e)[:100]}. Some optimization features will be limited.")
    # Define dummy classes for fallback
    class EfficientFrontier:
        def __init__(self, *args, **kwargs):
            pass
    class HRPOpt:
        def __init__(self, *args, **kwargs):
            pass

# Additional imports for enhanced functionality
from scipy.spatial.distance import squareform, pdist
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
# import networkx as nx

# Try to import optional packages with graceful fallbacks
try:
    import mplfinance as mpf
    MPLFINANCE_AVAILABLE = True
except ImportError:
    MPLFINANCE_AVAILABLE = False

try:
    from st_aggrid import AgGrid, GridOptionsBuilder
    AGGRID_AVAILABLE = True
except ImportError:
    AGGRID_AVAILABLE = False

warnings.filterwarnings("ignore")

# -------------------------------------------------------------
# ENHANCED GLOBAL ASSET UNIVERSE WITH SYMBOL MAPPING
# -------------------------------------------------------------
GLOBAL_ASSET_UNIVERSE = {
    # US Major Indices & ETFs
    "US_Indices": [
        "SPY", "QQQ", "IWM", "DIA", "VTI", "VOO", "IVV", 
        "VEA", "VWO", "VUG", "VO", "VB", "VTV", "XLK", "XLV",
        "XLF", "XLE", "XLI", "XLP", "XLY", "XLU", "XLB", "XLC"
    ],
    
    # Bonds & Fixed Income
    "Bonds": [
        "TLT", "IEF", "SHY", "BND", "AGG", "HYG", "JNK",
        "MUB", "TIP", "LQD", "EMB", "BIL", "GOVT", "MBB",
        "VCIT", "VCSH", "VTIP", "SCHZ", "SCHO", "SCHR"
    ],
    
    # Commodities
    "Commodities": [
        "GLD", "SLV", "USO", "UNG", "DBA", "PDBC", "GSG",
        "WEAT", "CORN", "SOYB", "CPER", "PALL", "PPLT",
        "DBB", "DBC", "JJG", "JJN", "JJC"
    ],
    
    # Cryptocurrencies
    "Cryptocurrencies": [
        "BTC-USD", "ETH-USD", "BNB-USD", "XRP-USD", "ADA-USD",
        "SOL-USD", "DOT-USD", "DOGE-USD", "MATIC-USD", "AVAX-USD",
        "LTC-USD", "UNI-USD", "LINK-USD", "ATOM-USD", "ETC-USD",
        "FIL-USD", "XLM-USD", "VET-USD", "TRX-USD", "ALGO-USD"
    ],
    
    # US Stocks - Technology
    "US_Tech_Stocks": [
        "AAPL", "MSFT", "GOOGL", "AMZN", "TSLA", "NVDA", "META",
        "AVGO", "ASML", "ORCL", "AMD", "INTC", "CSCO", "CRM",
        "ADBE", "NFLX", "PYPL", "QCOM", "TXN", "IBM"
    ],
    
    # US Stocks - Finance
    "US_Finance_Stocks": [
        "JPM", "BAC", "WFC", "C", "GS", "MS", "SCHW",
        "BLK", "AXP", "V", "MA", "PYPL", "COF", "DFS",
        "USB", "PNC", "TFC", "BK", "STT", "MMC"
    ],
    
    # US Stocks - Healthcare
    "US_Healthcare_Stocks": [
        "JNJ", "UNH", "PFE", "MRK", "ABT", "TMO", "ABBV",
        "LLY", "BMY", "AMGN", "CVS", "CI", "DHR", "SYK",
        "BDX", "ISRG", "GILD", "VRTX", "REGN", "HCA"
    ],
    
    # European Stocks
    "Europe_Stocks": [
        "ASML.AS", "SAP.DE", "SIE.DE", "ALV.DE", "DTE.DE",
        "NOVN.SW", "ROG.SW", "NESN.SW", "UBSG.SW", "CSGN.SW",
        "SAN.PA", "BNP.PA", "AIR.PA", "MC.PA", "OR.PA",
        "ENEL.MI", "ENI.MI", "ISP.MI", "UCG.MI", "AI.PA",
        "VOW3.DE", "BMW.DE", "DBK.DE", "BAS.DE", "LIN.DE"
    ],
    
    # UK Stocks
    "UK_Stocks": [
        "HSBA.L", "BP.L", "GSK.L", "RIO.L", "AAL.L",
        "AZN.L", "ULVR.L", "DGE.L", "BATS.L", "NG.L",
        "VOD.L", "LLOY.L", "BARCL.L", "BARC.L", "TSCO.L",
        "SHEL.L", "GLEN.L", "REL.L", "PRU.L", "LGEN.L"
    ],
    
    # Asia Pacific Stocks
    "Asia_Stocks": [
        "9988.HK", "0700.HK", "0388.HK", "0005.HK", "1299.HK",
        "7203.T", "8306.T", "9984.T", "6758.T", "6861.T",
        "BABA", "JD", "BIDU", "NTES", "TCEHY",
        "TSM", "SONY", "SNE", "MFG", "MUFG"
    ],
    
    # Emerging Markets
    "Emerging_Stocks": [
        "HDB", "INFY", "TCS.NS", "SBIN.NS", "RELIANCE.NS",
        "VALE", "ITUB", "BBD", "GGB", "ABEV", "SBS",
        "FMX", "AMX", "TEO", "PBR", "BSBR",
        "CHL", "CHU", "CEO", "PTR", "SNP"
    ],
    
    # Australia
    "Australia_Stocks": [
        "BHP.AX", "RIO.AX", "CBA.AX", "WBC.AX", "ANZ.AX",
        "NAB.AX", "CSL.AX", "WES.AX", "WOW.AX", "TLS.AX",
        "FMG.AX", "GMG.AX", "MQG.AX", "TCL.AX", "WPL.AX"
    ],
    
    # Singapore
    "Singapore_Stocks": [
        "D05.SI", "O39.SI", "U11.SI", "Z74.SI", "C09.SI",
        "G13.SI", "BN4.SI", "F34.SI", "C38U.SI", "ME8U.SI"
    ],
    
    # Turkey
    "Turkey_Stocks": [
        "AKBNK.IS", "GARAN.IS", "ISCTR.IS", "KOZAA.IS", "SAHOL.IS",
        "THYAO.IS", "TCELL.IS", "TUPRS.IS", "ARCLK.IS", "BIMAS.IS",
        "ASELS.IS", "HALKB.IS", "VAKBN.IS", "YKBNK.IS", "GARAN.IS"
    ],
    
    # Currencies & Forex with alternative symbols
    "Currencies": [
        "EURUSD=X", "EURUSD", "GBPUSD=X", "GBPUSD", 
        "USDJPY=X", "USDJPY", "USDCHF=X", "USDCHF",
        "AUDUSD=X", "AUDUSD", "USDCAD=X", "USDCAD", 
        "NZDUSD=X", "NZDUSD", "USDTRY=X", "USDTRY",
        "USDCNY=X", "USDCNY", "USDSGD=X", "USDSGD", 
        "USDHKD=X", "USDHKD", "USDINR=X", "USDINR",
        "USDBRL=X", "USDBRL", "USDZAR=X", "USDZAR", 
        "USDMXN=X", "USDMXN", "USDKRW=X", "USDKRW"
    ],
    
    # Volatility & Alternatives
    "Alternatives": [
        "^VIX", "VIXY", "UVXY", "SVXY", "SH",
        "TMF", "UPRO", "TQQQ", "SQQQ", "SPXU",
        "GDX", "GDXJ", "SLV", "USLV", "AGQ",
        "REET", "VNQ", "IYR", "REM", "MORT"
    ],
    
    # Real Estate
    "Real_Estate": [
        "VNQ", "IYR", "XLRE", "SCHH", "FREL",
        "REZ", "ROOF", "SRET", "MORT", "REM",
        "O", "AMT", "PLD", "CCI", "EQIX",
        "PSA", "AVB", "EQR", "DLR", "WELL"
    ],
    
    # Infrastructure
    "Infrastructure": [
        "IFRA", "PAVE", "MLPX", "UTG", "UTF",
        "NLR", "URA", "REMX", "PICK", "WOOD",
        "TAN", "ICLN", "PBW", "QCLN", "FAN"
    ],
    
    # Smart Beta & Factors
    "Smart_Beta": [
        "MTUM", "QUAL", "USMV", "VLUE", "SIZE",
        "VFVA", "FNDB", "FNDX", "FNDA", "FNDF",
        "IWF", "IWD", "IWM", "IWN", "IWO"
    ]
}

# Enhanced Symbol mapping for common variations
SYMBOL_MAPPING = {
    "BTC-USD": ["BTC-USD", "BTCUSD", "BTCUSDT", "BTC-USD"],
    "ETH-USD": ["ETH-USD", "ETHUSD", "ETHUSDT", "ETH-USD"],
    "BRK-B": ["BRK-B", "BRK.B", "BRK_B"],
    "GOOGL": ["GOOGL", "GOOG"],
    "EURUSD=X": ["EURUSD=X", "EURUSD", "EUR/USD"],
    "GBPUSD=X": ["GBPUSD=X", "GBPUSD", "GBP/USD"],
    "USDJPY=X": ["USDJPY=X", "USDJPY", "USD/JPY"],
    "USDCHF=X": ["USDCHF=X", "USDCHF", "USD/CHF"],
    "AUDUSD=X": ["AUDUSD=X", "AUDUSD", "AUD/USD"],
    "USDCAD=X": ["USDCAD=X", "USDCAD", "USD/CAD"],
    "NZDUSD=X": ["NZDUSD=X", "NZDUSD", "NZD/USD"],
    "VOW3.DE": ["VOW3.DE", "VOW.DE", "VOW3.DE"],
    "BMW.DE": ["BMW.DE", "BMW.DE"],
    "DBK.DE": ["DBK.DE", "DBK.DE"],
}

# Flatten universe for selection
ALL_TICKERS = []
for category in GLOBAL_ASSET_UNIVERSE.values():
    ALL_TICKERS.extend(category)
ALL_TICKERS = list(dict.fromkeys(ALL_TICKERS))  # Remove duplicates while preserving order

# -------------------------------------------------------------
# CONFIGURATION
# -------------------------------------------------------------
APP_TITLE = "üèõÔ∏è Apollo/ENIGMA - Global Portfolio Terminal v6.0"
DEFAULT_RF_ANNUAL = 0.03
TRADING_DAYS = 252
MONTE_CARLO_SIMULATIONS = 10000
MAX_CACHE_SIZE = 100
CACHE_DIR = tempfile.gettempdir() + "/apollo_cache/"

os.environ["NUMEXPR_MAX_THREADS"] = "8"
os.environ["OMP_NUM_THREADS"] = "4"
os.environ["MKL_NUM_THREADS"] = "4"

# Create cache directory if it doesn't exist
Path(CACHE_DIR).mkdir(parents=True, exist_ok=True)

# Initialize Streamlit with wide layout
st.set_page_config(
    page_title="Apollo/ENIGMA - Global Portfolio Terminal",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üìä"
)

# -------------------------------------------------------------
# ENHANCED INSTITUTIONAL THEME WITH 3D SUPPORT
# -------------------------------------------------------------
st.markdown("""
<style>
:root {
    --primary: #1a5fb4;
    --primary-dark: #0d4fa0;
    --secondary: #26a269;
    --secondary-dark: #1e864d;
    --tertiary: #9141ac;
    --tertiary-dark: #7a3394;
    --danger: #c01c28;
    --danger-dark: #9a1a23;
    --warning: #f5a623;
    --warning-dark: #d48e1e;
    --dark-bg: #0f172a;
    --dark-bg-light: #1e293b;
    --card-bg: #1e293b;
    --card-bg-light: #2d3748;
    --border: #334155;
    --border-light: #475569;
    --text: #f1f5f9;
    --text-muted: #94a3b8;
    --text-light: #e2e8f0;
    --success: #16a34a;
    --success-dark: #15803d;
    --info: #3b82f6;
    --info-dark: #2563eb;
    --chart-1: #3b82f6;
    --chart-2: #10b981;
    --chart-3: #f59e0b;
    --chart-4: #ef4444;
    --chart-5: #8b5cf6;
    --chart-6: #ec4899;
}

/* Enhanced tabs */
.stTabs [data-baseweb="tab-list"] {
    gap: 2px;
    background-color: var(--dark-bg-light);
    padding: 4px;
    border-radius: 10px;
    border: 1px solid var(--border);
}

.stTabs [data-baseweb="tab"] {
    background-color: transparent;
    border-radius: 8px;
    padding: 10px 20px;
    font-weight: 500;
    color: var(--text-muted);
    border: 1px solid transparent;
    transition: all 0.3s ease;
}

.stTabs [data-baseweb="tab"]:hover {
    background-color: var(--card-bg);
    color: var(--text-light);
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(135deg, var(--primary), var(--primary-dark)) !important;
    color: white !important;
    border-color: var(--primary) !important;
    box-shadow: 0 4px 12px rgba(26, 95, 180, 0.3);
}

/* Professional KPI cards */
.kpi-card {
    background: linear-gradient(145deg, var(--card-bg), #1a2332);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 20px;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.25);
    transition: all 0.3s ease;
    height: 120px;
    display: flex;
    flex-direction: column;
    justify-content: center;
    position: relative;
    overflow: hidden;
}

.kpi-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 4px;
    background: linear-gradient(90deg, var(--primary), var(--secondary));
}

.kpi-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 30px rgba(0, 0, 0, 0.35);
    border-color: var(--primary);
}

.kpi-value {
    font-size: 28px;
    font-weight: 700;
    color: var(--text);
    margin: 8px 0;
    line-height: 1.2;
    text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
}

.kpi-label {
    font-size: 13px;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.5px;
    font-weight: 500;
}

/* Enhanced metrics */
[data-testid="metric-container"] {
    background: var(--card-bg) !important;
    border: 1px solid var(--border) !important;
    border-radius: 12px !important;
    padding: 20px !important;
    transition: all 0.3s ease;
}

[data-testid="metric-container"]:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(0, 0, 0, 0.2);
    border-color: var(--primary) !important;
}

[data-testid="metric-container"] label {
    color: var(--text-muted) !important;
    font-size: 14px !important;
    font-weight: 500 !important;
}

[data-testid="metric-container"] div {
    color: var(--text) !important;
    font-size: 24px !important;
    font-weight: 700 !important;
}

/* Buttons */
.stButton > button {
    background: linear-gradient(135deg, var(--primary), var(--primary-dark));
    color: white;
    border: none;
    padding: 12px 24px;
    border-radius: 8px;
    font-weight: 600;
    transition: all 0.3s;
    width: 100%;
    box-shadow: 0 4px 12px rgba(26, 95, 180, 0.3);
    position: relative;
    overflow: hidden;
}

.stButton > button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
    transition: 0.5s;
}

.stButton > button:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(26, 95, 180, 0.4);
}

.stButton > button:hover::before {
    left: 100%;
}

/* Secondary buttons */
.secondary-button > button {
    background: linear-gradient(135deg, var(--secondary), var(--secondary-dark));
}

.tertiary-button > button {
    background: linear-gradient(135deg, var(--tertiary), var(--tertiary-dark));
}

.danger-button > button {
    background: linear-gradient(135deg, var(--danger), var(--danger-dark));
}

.warning-button > button {
    background: linear-gradient(135deg, var(--warning), var(--warning-dark));
}

/* Status indicators */
.status-success { 
    color: var(--success) !important;
    font-weight: 600;
}
.status-warning { 
    color: var(--warning) !important;
    font-weight: 600;
}
.status-error { 
    color: var(--danger) !important;
    font-weight: 600;
}
.status-info {
    color: var(--info) !important;
    font-weight: 600;
}
.status-primary {
    color: var(--primary) !important;
    font-weight: 600;
}

/* Custom scrollbar */
::-webkit-scrollbar {
    width: 8px;
    height: 8px;
}

::-webkit-scrollbar-track {
    background: var(--dark-bg);
    border-radius: 4px;
}

::-webkit-scrollbar-thumb {
    background: linear-gradient(var(--primary), var(--primary-dark));
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: linear-gradient(var(--primary-dark), var(--primary));
}

/* Card enhancements */
.card {
    background: var(--card-bg);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 20px;
    margin-bottom: 20px;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
}

.card-header {
    font-size: 1.2rem;
    font-weight: 600;
    margin-bottom: 15px;
    color: var(--text);
    border-bottom: 1px solid var(--border);
    padding-bottom: 10px;
    display: flex;
    align-items: center;
    gap: 10px;
}

.card-header::before {
    content: '‚Ä¢';
    color: var(--primary);
    font-size: 1.5em;
}

/* Progress bars */
.stProgress > div > div > div {
    background: linear-gradient(90deg, var(--primary), var(--secondary));
    border-radius: 4px;
}

/* Select boxes and inputs */
.stSelectbox > div > div, .stTextInput > div > div {
    background: var(--card-bg) !important;
    border: 1px solid var(--border) !important;
    border-radius: 8px !important;
}

.stSelectbox > div > div:hover, .stTextInput > div > div:hover {
    border-color: var(--primary) !important;
}

/* Slider customization */
.stSlider > div > div > div {
    background: linear-gradient(90deg, var(--primary), var(--secondary)) !important;
}

/* Data tables */
.stDataFrame {
    border: 1px solid var(--border) !important;
    border-radius: 10px !important;
    overflow: hidden !important;
}

.stDataFrame table {
    background: var(--card-bg) !important;
}

.stDataFrame thead {
    background: var(--dark-bg-light) !important;
}

.stDataFrame th {
    color: var(--text) !important;
    font-weight: 600 !important;
    border-bottom: 2px solid var(--border) !important;
}

.stDataFrame td {
    color: var(--text-light) !important;
    border-bottom: 1px solid var(--border-light) !important;
}

/* Expanders */
.streamlit-expanderHeader {
    background: var(--card-bg) !important;
    border: 1px solid var(--border) !important;
    border-radius: 8px !important;
    color: var(--text) !important;
    font-weight: 600 !important;
}

.streamlit-expanderHeader:hover {
    background: var(--card-bg-light) !important;
    border-color: var(--primary) !important;
}

/* Alerts and info boxes */
.stAlert {
    border-radius: 10px !important;
    border: 1px solid !important;
}

/* Plotly chart container */
.js-plotly-plot {
    border-radius: 12px;
    overflow: hidden;
    border: 1px solid var(--border);
}

/* Tooltips */
[title] {
    position: relative;
}

[title]:hover::after {
    content: attr(title);
    position: absolute;
    bottom: 100%;
    left: 50%;
    transform: translateX(-50%);
    background: var(--dark-bg);
    color: var(--text);
    padding: 8px 12px;
    border-radius: 6px;
    font-size: 12px;
    white-space: nowrap;
    z-index: 1000;
    border: 1px solid var(--border);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
}

/* Badges */
.badge {
    display: inline-block;
    padding: 4px 8px;
    border-radius: 12px;
    font-size: 11px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.badge-primary {
    background: linear-gradient(135deg, var(--primary), var(--primary-dark));
    color: white;
}

.badge-secondary {
    background: linear-gradient(135deg, var(--secondary), var(--secondary-dark));
    color: white;
}

.badge-tertiary {
    background: linear-gradient(135deg, var(--tertiary), var(--tertiary-dark));
    color: white;
}

.badge-success {
    background: linear-gradient(135deg, var(--success), var(--success-dark));
    color: white;
}

.badge-warning {
    background: linear-gradient(135deg, var(--warning), var(--warning-dark));
    color: white;
}

.badge-danger {
    background: linear-gradient(135deg, var(--danger), var(--danger-dark));
    color: white;
}

/* Grid layout */
.grid-container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 20px;
    margin-bottom: 20px;
}

/* Loading spinner */
.stSpinner > div {
    border: 3px solid var(--border);
    border-top: 3px solid var(--primary);
    border-radius: 50%;
    width: 40px;
    height: 40px;
    animation: spin 1s linear infinite;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

/* 3D View Controls */
.view-controls {
    background: var(--card-bg-light);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 10px;
    margin-bottom: 10px;
}

/* Matrix container */
.matrix-container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 10px;
    padding: 10px;
    background: var(--dark-bg-light);
    border-radius: 8px;
}

/* Metric grid */
.metric-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: 15px;
    margin: 20px 0;
}

.metric-item {
    background: var(--card-bg-light);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 15px;
    transition: all 0.3s ease;
}

.metric-item:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
    border-color: var(--primary);
}

.metric-value {
    font-size: 24px;
    font-weight: 700;
    color: var(--text);
    margin: 5px 0;
}

.metric-label {
    font-size: 12px;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

/* Risk meter */
.risk-meter {
    width: 100%;
    height: 8px;
    background: var(--border-light);
    border-radius: 4px;
    overflow: hidden;
    margin: 10px 0;
}

.risk-level {
    height: 100%;
    border-radius: 4px;
    transition: width 0.5s ease;
}

/* Heatmap styles */
.heatmap-container {
    border-radius: 12px;
    overflow: hidden;
    border: 1px solid var(--border);
}

/* Responsive adjustments */
@media (max-width: 768px) {
    .grid-container {
        grid-template-columns: 1fr;
    }
    
    .kpi-card {
        height: auto;
        min-height: 100px;
    }
    
    .kpi-value {
        font-size: 24px;
    }
    
    .metric-grid {
        grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
    }
}
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# DATA CLASSES FOR STRUCTURED DATA
# -------------------------------------------------------------
@dataclass
class PortfolioMetrics:
    """Comprehensive portfolio metrics container"""
    # Basic metrics
    expected_return: float = 0.0
    expected_volatility: float = 0.0
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    max_drawdown: float = 0.0
    calmar_ratio: float = 0.0
    
    # Risk metrics
    var_95: float = 0.0
    cvar_95: float = 0.0
    omega_ratio: float = 0.0
    tail_ratio: float = 0.0
    skewness: float = 0.0
    kurtosis: float = 0.0
    
    # Advanced metrics
    information_ratio: float = 0.0
    tracking_error: float = 0.0
    beta: float = 0.0
    alpha: float = 0.0
    treynor_ratio: float = 0.0
    
    # Drawdown metrics
    avg_drawdown: float = 0.0
    max_drawdown_duration: int = 0
    recovery_factor: float = 0.0
    
    # Performance metrics
    cumulative_return: float = 0.0
    annual_return: float = 0.0
    annual_volatility: float = 0.0
    downside_deviation: float = 0.0
    
    # Ratios
    gain_to_pain_ratio: float = 0.0
    ulcer_index: float = 0.0
    m2_ratio: float = 0.0
    m3_ratio: float = 0.0
    m4_ratio: float = 0.0
    
    # Custom metrics
    diversification_ratio: float = 0.0
    concentration_ratio: float = 0.0
    risk_parity_score: float = 0.0

@dataclass
class OptimizationResult:
    """Optimization results container"""
    weights: pd.Series
    expected_return: float
    expected_volatility: float
    sharpe_ratio: float
    strategy: str
    parameters: Dict[str, Any]
    metrics: PortfolioMetrics
    efficient_frontier: Optional[pd.DataFrame] = None
    cluster_matrix: Optional[pd.DataFrame] = None
    risk_contributions: Optional[pd.Series] = None

# -------------------------------------------------------------
# PORTFOLIO STRATEGIES WITH ENHANCED PARAMETERS
# -------------------------------------------------------------
PORTFOLIO_STRATEGIES = {
    "Equal Weight": {
        "description": "Equal allocation across all selected assets",
        "parameters": {}
    },
    "Minimum Volatility": {
        "description": "Optimized for lowest portfolio volatility",
        "parameters": {
            "market_neutral": {"type": "bool", "default": False},
            "regularization": {"type": "float", "default": 0.1, "min": 0, "max": 1}
        }
    },
    "Maximum Sharpe Ratio": {
        "description": "Optimized for highest risk-adjusted returns",
        "parameters": {
            "risk_free_rate": {"type": "float", "default": 0.03, "min": 0, "max": 0.1},
            "market_neutral": {"type": "bool", "default": False}
        }
    },
    "Maximum Quadratic Utility": {
        "description": "Balances return and risk based on risk aversion",
        "parameters": {
            "risk_aversion": {"type": "float", "default": 1.0, "min": 0.1, "max": 10},
            "market_neutral": {"type": "bool", "default": False}
        }
    },
    "Efficient Risk": {
        "description": "Optimizes for maximum return at given risk level",
        "parameters": {
            "target_volatility": {"type": "float", "default": 0.15, "min": 0.05, "max": 0.5},
            "market_neutral": {"type": "bool", "default": False}
        }
    },
    "Efficient Return": {
        "description": "Optimizes for minimum risk at given return target",
        "parameters": {
            "target_return": {"type": "float", "default": 0.10, "min": 0.01, "max": 0.50},
            "market_neutral": {"type": "bool", "default": False}
        }
    },
    "Risk Parity": {
        "description": "Equal risk contribution from each asset",
        "parameters": {
            "risk_budget": {"type": "select", "options": ["Equal", "Custom"], "default": "Equal"}
        }
    },
    "Maximum Diversification": {
        "description": "Maximizes diversification ratio",
        "parameters": {
            "regularization": {"type": "float", "default": 0.1, "min": 0, "max": 1}
        }
    },
    "Mean-Variance Optimal": {
        "description": "Classical Markowitz optimization",
        "parameters": {
            "gamma": {"type": "float", "default": 0.5, "min": 0, "max": 2},
            "market_neutral": {"type": "bool", "default": False}
        }
    },
    "Hierarchical Risk Parity": {
        "description": "Uses hierarchical clustering for diversification",
        "parameters": {
            "linkage_method": {"type": "select", "options": ["single", "complete", "average", "ward"], "default": "single"},
            "cov_estimation": {"type": "select", "options": ["sample", "ledoit_wolf", "oracle_approximating"], "default": "sample"}
        }
    },
    "Minimum CVaR": {
        "description": "Minimizes Conditional Value at Risk",
        "parameters": {
            "confidence_level": {"type": "float", "default": 0.95, "min": 0.90, "max": 0.99},
            "s": {"type": "int", "default": 10000, "min": 1000, "max": 100000}
        }
    },
    "Black-Litterman": {
        "description": "Combines market equilibrium with investor views",
        "parameters": {
            "view_confidences": {"type": "str", "default": "0.5,0.5", "help": "Comma-separated confidences for each view"},
            "risk_aversion": {"type": "float", "default": 1.0, "min": 0.1, "max": 10}
        }
    },
    "Custom Weights": {
        "description": "Manually specify asset weights",
        "parameters": {
            "weights": {"type": "dict", "default": {}},
            "normalize": {"type": "bool", "default": True}
        }
    }
}

# -------------------------------------------------------------
# ENHANCED CACHING SYSTEM WITH METRICS
# -------------------------------------------------------------
class EnhancedCache:
    """Enhanced caching system for better performance with persistence"""
    
    @staticmethod
    def get_cache_key(*args, **kwargs):
        """Generate a unique cache key from function arguments"""
        call_frame = inspect.currentframe().f_back
        func_name = call_frame.f_code.co_name
        
        # Create a string representation of arguments
        args_str = ''.join([str(arg) for arg in args])
        kwargs_str = ''.join([f"{k}{v}" for k, v in sorted(kwargs.items())])
        
        # Generate MD5 hash
        key_string = f"{func_name}_{args_str}_{kwargs_str}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    @staticmethod
    def cache_data(data, key, ttl_seconds=3600, metadata=None):
        """Cache data with TTL and metadata"""
        cache_file = Path(CACHE_DIR) / f"{key}.pkl"
        
        cache_entry = {
            'data': data,
            'timestamp': time.time(),
            'ttl': ttl_seconds,
            'metadata': metadata or {}
        }
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_entry, f, protocol=pickle.HIGHEST_PROTOCOL)
            return True
        except Exception as e:
            logger.warning(f"Cache write failed: {str(e)}")
            return False
    
    @staticmethod
    def get_cached_data(key):
        """Retrieve cached data if not expired"""
        cache_file = Path(CACHE_DIR) / f"{key}.pkl"
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'rb') as f:
                cache_entry = pickle.load(f)
            
            # Check if cache is expired
            if time.time() - cache_entry['timestamp'] > cache_entry['ttl']:
                try:
                    cache_file.unlink(missing_ok=True)
                except:
                    pass
                return None
            
            return cache_entry['data']
        except Exception as e:
            try:
                cache_file.unlink(missing_ok=True)
            except:
                pass
            logger.warning(f"Cache read failed: {str(e)}")
            return None
    
    @staticmethod
    def clear_cache():
        """Clear all cache files"""
        cache_dir = Path(CACHE_DIR)
        if cache_dir.exists():
            for file in cache_dir.glob("*.pkl"):
                try:
                    file.unlink()
                except:
                    pass
            return True
        return False
    
    @staticmethod
    def get_cache_stats():
        """Get cache statistics"""
        cache_dir = Path(CACHE_DIR)
        if not cache_dir.exists():
            return {"total_files": 0, "total_size_mb": 0, "hit_rate": 0}
        
        files = list(cache_dir.glob("*.pkl"))
        total_size = sum(f.stat().st_size for f in files if f.exists())
        
        return {
            "total_files": len(files),
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "cache_dir": str(cache_dir)
        }

# -------------------------------------------------------------
# DECORATORS FOR SAFE EXECUTION
# -------------------------------------------------------------
def safe_execution(default_return=None, show_warning=True):
    """Decorator for safe function execution with fallback"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if show_warning:
                    st.warning(f"{func.__name__} failed: {str(e)[:100]}")
                logger.error(f"Error in {func.__name__}: {str(e)}")
                logger.error(traceback.format_exc())
                return default_return
        return wrapper
    return decorator

def timed_execution(func):
    """Decorator to measure execution time"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        logger.info(f"{func.__name__} executed in {end_time - start_time:.2f} seconds")
        return result
    return wrapper

# -------------------------------------------------------------
# ENHANCED DATA LOADING WITH PARALLEL PROCESSING
# -------------------------------------------------------------
@safe_execution(default_return=(None, None))
def download_single_ticker(ticker, start_date, end_date, max_retries=3, timeout=15):
    """Download data for a single ticker with retry logic and symbol fallback"""
    # Ensure dates are strings
    if not isinstance(start_date, str):
        start_date = str(start_date)
    if not isinstance(end_date, str):
        end_date = str(end_date)
    
    for attempt in range(max_retries):
        try:
            # Try alternative symbols first
            symbols_to_try = [ticker]
            if ticker in SYMBOL_MAPPING:
                symbols_to_try = SYMBOL_MAPPING[ticker] + symbols_to_try
            
            for symbol in symbols_to_try:
                try:
                    ticker_obj = yf.Ticker(symbol)
                    
                    # Get info to check if ticker exists
                    info = ticker_obj.info
                    if not info:
                        continue
                    
                    # Try different intervals if daily fails
                    hist = ticker_obj.history(
                        start=start_date,
                        end=end_date,
                        interval="1d",
                        auto_adjust=True,
                        prepost=False,
                        timeout=timeout
                    )
                    
                    if not hist.empty and len(hist) > 10:
                        # Use adjusted close if available, otherwise close
                        if 'Close' in hist.columns:
                            price_series = hist['Close'].copy()
                        elif 'Adj Close' in hist.columns:
                            price_series = hist['Adj Close'].copy()
                        else:
                            continue
                        
                        # Remove any extreme outliers
                        median_price = price_series.median()
                        std_price = price_series.std()
                        if std_price > 0:
                            # Cap at 10 standard deviations
                            lower_bound = median_price - 10 * std_price
                            upper_bound = median_price + 10 * std_price
                            price_series = price_series.clip(lower_bound, upper_bound)
                        
                        return symbol, price_series
                        
                except Exception as e:
                    if attempt == max_retries - 1:
                        logger.debug(f"Failed to download {symbol}: {str(e)}")
                    continue
            
            # Try batch download as fallback
            try:
                data = yf.download(
                    ticker,
                    start=start_date,
                    end=end_date,
                    progress=False,
                    threads=False,
                    auto_adjust=True,
                    timeout=timeout
                )
                if not data.empty and 'Close' in data.columns:
                    return ticker, data['Close']
            except Exception as e:
                if attempt == max_retries - 1:
                    logger.debug(f"Batch download failed for {ticker}: {str(e)}")
                
        except Exception as e:
            if attempt == max_retries - 1:
                logger.debug(f"Final attempt failed for {ticker}: {str(e)}")
            time.sleep(0.5 * (attempt + 1))  # Exponential backoff
    
    return ticker, None

@st.cache_data(show_spinner=False, ttl=3600, max_entries=20)
@timed_execution
def load_global_prices_enhanced(tickers: List[str], start_date: str, end_date: str, 
                               use_parallel: bool = True) -> pd.DataFrame:
    """Load global asset prices with enhanced error handling and parallel downloads"""
    
    if not tickers:
        return pd.DataFrame()
    
    # Create progress indicators
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    prices_dict = {}
    successful_tickers = []
    failed_tickers = []
    
    start_time = time.time()
    
    if use_parallel and len(tickers) > 5:
        # Parallel download for larger sets
        max_workers = min(8, len(tickers))
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit all download tasks
            future_to_ticker = {
                executor.submit(download_single_ticker, ticker, start_date, end_date): ticker 
                for ticker in tickers
            }
            
            # Process completed tasks
            completed = 0
            total = len(tickers)
            
            for future in concurrent.futures.as_completed(future_to_ticker):
                ticker = future_to_ticker[future]
                completed += 1
                
                try:
                    symbol, price_data = future.result(timeout=20)
                    if price_data is not None and len(price_data) > 10:
                        prices_dict[symbol] = price_data
                        successful_tickers.append(symbol)
                    else:
                        failed_tickers.append(ticker)
                except Exception as e:
                    failed_tickers.append(ticker)
                
                # Update progress
                progress = completed / total
                progress_bar.progress(progress)
                status_text.text(f"Downloaded {completed}/{total} assets...")
        
    else:
        # Sequential download for small sets
        total = len(tickers)
        for i, ticker in enumerate(tickers):
            symbol, price_data = download_single_ticker(ticker, start_date, end_date)
            if price_data is not None and len(price_data) > 10:
                prices_dict[symbol] = price_data
                successful_tickers.append(symbol)
            else:
                failed_tickers.append(ticker)
            
            # Update progress
            progress = (i + 1) / total
            progress_bar.progress(progress)
            status_text.text(f"Downloaded {i+1}/{total} assets...")
    
    progress_bar.empty()
    status_text.empty()
    
    # Create DataFrame
    if prices_dict:
        prices_df = pd.DataFrame(prices_dict)
        prices_df = prices_df.sort_index()
        
        # Forward fill and backward fill missing values
        prices_df = prices_df.ffill().bfill()
        
        # Remove any remaining NaN columns
        prices_df = prices_df.dropna(axis=1, how='all')
        
        # Log results
        elapsed_time = time.time() - start_time
        logger.info(f"Downloaded {len(prices_df.columns)} assets in {elapsed_time:.2f} seconds")
        
        if failed_tickers:
            st.warning(f"Failed to download {len(failed_tickers)} assets: {', '.join(failed_tickers[:10])}")
        
        return prices_df
    else:
        st.error("Failed to download any asset data. Please check your internet connection and ticker symbols.")
        return pd.DataFrame()

# -------------------------------------------------------------
# ADVANCED PORTFOLIO OPTIMIZATION FUNCTIONS
# -------------------------------------------------------------
@safe_execution(default_return=None)
def calculate_portfolio_metrics(returns: pd.DataFrame, weights: pd.Series, 
                               risk_free_rate: float = 0.03) -> PortfolioMetrics:
    """Calculate comprehensive portfolio metrics"""
    
    # Calculate portfolio returns
    portfolio_returns = (returns * weights).sum(axis=1)
    
    # Calculate basic metrics
    expected_return = portfolio_returns.mean() * TRADING_DAYS
    expected_volatility = portfolio_returns.std() * np.sqrt(TRADING_DAYS)
    sharpe_ratio = (expected_return - risk_free_rate) / expected_volatility if expected_volatility > 0 else 0
    
    # Calculate Sortino ratio (using downside deviation)
    downside_returns = portfolio_returns[portfolio_returns < 0]
    downside_deviation = downside_returns.std() * np.sqrt(TRADING_DAYS) if len(downside_returns) > 0 else 0
    sortino_ratio = (expected_return - risk_free_rate) / downside_deviation if downside_deviation > 0 else 0
    
    # Calculate cumulative returns and drawdowns
    cumulative_returns = (1 + portfolio_returns).cumprod()
    running_max = cumulative_returns.expanding().max()
    drawdown = (cumulative_returns - running_max) / running_max
    max_drawdown = drawdown.min()
    calmar_ratio = expected_return / abs(max_drawdown) if max_drawdown != 0 else 0
    
    # Calculate VaR and CVaR
    var_95 = np.percentile(portfolio_returns, 5) * np.sqrt(TRADING_DAYS)
    cvar_95 = portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)].mean() * np.sqrt(TRADING_DAYS)
    
    # Calculate Omega ratio
    threshold = risk_free_rate / TRADING_DAYS
    gains = portfolio_returns[portfolio_returns > threshold].sum()
    losses = abs(portfolio_returns[portfolio_returns < threshold].sum())
    omega_ratio = gains / losses if losses != 0 else float('inf')
    
    # Calculate skewness and kurtosis
    skewness = skew(portfolio_returns)
    excess_kurtosis = kurtosis(portfolio_returns)
    
    # Calculate tail ratio
    tail_ratio = abs(np.percentile(portfolio_returns, 95) / np.percentile(portfolio_returns, 5))
    
    # Calculate Ulcer Index
    ulcer_index = np.sqrt(np.mean(drawdown ** 2)) * 100
    
    # Calculate recovery factor
    recovery_factor = abs(cumulative_returns.iloc[-1] - 1) / abs(max_drawdown) if max_drawdown != 0 else 0
    
    # Calculate Gain to Pain ratio
    total_gain = portfolio_returns[portfolio_returns > 0].sum()
    total_pain = abs(portfolio_returns[portfolio_returns < 0].sum())
    gain_to_pain_ratio = total_gain / total_pain if total_pain != 0 else float('inf')
    
    # Calculate M2, M3, M4 ratios
    m2_ratio = sharpe_ratio * expected_volatility + risk_free_rate
    m3_ratio = sortino_ratio * downside_deviation + risk_free_rate
    
    # Create metrics object
    metrics = PortfolioMetrics(
        expected_return=expected_return,
        expected_volatility=expected_volatility,
        sharpe_ratio=sharpe_ratio,
        sortino_ratio=sortino_ratio,
        max_drawdown=max_drawdown,
        calmar_ratio=calmar_ratio,
        var_95=var_95,
        cvar_95=cvar_95,
        omega_ratio=omega_ratio,
        tail_ratio=tail_ratio,
        skewness=skewness,
        kurtosis=excess_kurtosis,
        downside_deviation=downside_deviation,
        cumulative_return=cumulative_returns.iloc[-1] - 1,
        annual_return=expected_return,
        annual_volatility=expected_volatility,
        gain_to_pain_ratio=gain_to_pain_ratio,
        ulcer_index=ulcer_index,
        m2_ratio=m2_ratio,
        m3_ratio=m3_ratio,
        m4_ratio=0,  # Placeholder
        avg_drawdown=drawdown.mean(),
        max_drawdown_duration=(drawdown == max_drawdown).sum(),
        recovery_factor=recovery_factor
    )
    
    return metrics

@safe_execution(default_return=None)
def optimize_portfolio_strategy(returns: pd.DataFrame, strategy: str, 
                               risk_free_rate: float = 0.03, **kwargs) -> OptimizationResult:
    """Optimize portfolio based on selected strategy"""
    
    if not PYPFOPT_AVAILABLE:
        st.error("PyPortfolioOpt is required for optimization. Please install it.")
        return None
    
    # Get expected returns and covariance matrix
    mu = expected_returns.mean_historical_return(returns)
    cov_matrix = risk_models.sample_cov(returns)
    
    # Initialize based on strategy
    if strategy == "Equal Weight":
        weights = pd.Series([1/len(returns.columns)] * len(returns.columns), index=returns.columns)
        
    elif strategy == "Minimum Volatility":
        ef = EfficientFrontier(mu, cov_matrix)
        ef.min_volatility()
        weights = ef.clean_weights()
        
    elif strategy == "Maximum Sharpe Ratio":
        ef = EfficientFrontier(mu, cov_matrix)
        ef.max_sharpe(risk_free_rate=risk_free_rate)
        weights = ef.clean_weights()
        
    elif strategy == "Maximum Quadratic Utility":
        risk_aversion = kwargs.get('risk_aversion', 1.0)
        ef = EfficientFrontier(mu, cov_matrix)
        ef.max_quadratic_utility(risk_aversion=risk_aversion)
        weights = ef.clean_weights()
        
    elif strategy == "Efficient Risk":
        target_volatility = kwargs.get('target_volatility', 0.15)
        ef = EfficientFrontier(mu, cov_matrix)
        ef.efficient_risk(target_volatility=target_volatility)
        weights = ef.clean_weights()
        
    elif strategy == "Efficient Return":
        target_return = kwargs.get('target_return', 0.10)
        ef = EfficientFrontier(mu, cov_matrix)
        ef.efficient_return(target_return=target_return)
        weights = ef.clean_weights()
        
    elif strategy == "Risk Parity":
        # Simple risk parity implementation
        vols = returns.std()
        inverse_vols = 1 / vols
        weights = inverse_vols / inverse_vols.sum()
        
    elif strategy == "Maximum Diversification":
        # Calculate diversification ratio
        vols = returns.std()
        corr_matrix = returns.corr()
        weights = pd.Series(1/vols, index=returns.columns)
        weights = weights / weights.sum()
        
    elif strategy == "Mean-Variance Optimal":
        gamma = kwargs.get('gamma', 0.5)
        ef = EfficientFrontier(mu, cov_matrix)
        weights = pd.Series(ef.max_quadratic_utility(risk_aversion=gamma), index=returns.columns)
        
    elif strategy == "Hierarchical Risk Parity" and PYPFOPT_AVAILABLE:
        hrp = HRPOpt(returns)
        hrp.optimize()
        weights = hrp.clean_weights()
        
    elif strategy == "Minimum CVaR" and PYPFOPT_AVAILABLE:
        confidence_level = kwargs.get('confidence_level', 0.95)
        ef_cvar = EfficientCVaR(mu, returns, beta=confidence_level)
        ef_cvar.min_cvar()
        weights = ef_cvar.clean_weights()
        
    elif strategy == "Black-Litterman" and PYPFOPT_AVAILABLE:
        # Simplified Black-Litterman implementation
        market_cap = pd.Series([1] * len(returns.columns), index=returns.columns)
        bl = black_litterman.BlackLittermanModel(cov_matrix, pi=mu, absolute_views={})
        bl_returns = bl.bl_returns()
        bl_cov = bl.bl_cov()
        ef = EfficientFrontier(bl_returns, bl_cov)
        ef.max_sharpe()
        weights = ef.clean_weights()
        
    elif strategy == "Custom Weights":
        custom_weights = kwargs.get('weights', {})
        if custom_weights:
            weights = pd.Series(custom_weights)
        else:
            weights = pd.Series([1/len(returns.columns)] * len(returns.columns), index=returns.columns)
    
    else:
        # Default to equal weight
        weights = pd.Series([1/len(returns.columns)] * len(returns.columns), index=returns.columns)
    
    # Ensure weights sum to 1
    weights = weights / weights.sum()
    
    # Calculate portfolio metrics
    metrics = calculate_portfolio_metrics(returns, weights, risk_free_rate)
    
    # Calculate efficient frontier
    ef = EfficientFrontier(mu, cov_matrix)
    ef_returns, ef_volatilities, ef_sharpes = [], [], []
    
    for target_return in np.linspace(mu.min(), mu.max(), 50):
        try:
            ef.efficient_return(target_return=target_return)
            weights_ef = ef.clean_weights()
            portfolio_return = np.sum(mu * pd.Series(weights_ef))
            portfolio_vol = np.sqrt(np.dot(pd.Series(weights_ef).T, np.dot(cov_matrix, pd.Series(weights_ef))))
            ef_returns.append(portfolio_return)
            ef_volatilities.append(portfolio_vol)
            ef_sharpes.append((portfolio_return - risk_free_rate) / portfolio_vol if portfolio_vol > 0 else 0)
        except:
            continue
    
    efficient_frontier = pd.DataFrame({
        'Return': ef_returns,
        'Volatility': ef_volatilities,
        'Sharpe': ef_sharpes
    })
    
    # Calculate risk contributions
    portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol if portfolio_vol > 0 else np.zeros_like(weights)
    risk_contributions = pd.Series(weights * marginal_contrib, index=weights.index)
    
    # Create optimization result
    result = OptimizationResult(
        weights=weights,
        expected_return=metrics.expected_return,
        expected_volatility=metrics.expected_volatility,
        sharpe_ratio=metrics.sharpe_ratio,
        strategy=strategy,
        parameters=kwargs,
        metrics=metrics,
        efficient_frontier=efficient_frontier,
        risk_contributions=risk_contributions
    )
    
    return result

@safe_execution(default_return=pd.DataFrame())
def run_monte_carlo_simulation(returns: pd.DataFrame, n_simulations: int = 10000) -> pd.DataFrame:
    """Run Monte Carlo simulation for portfolio optimization"""
    
    mean_returns = returns.mean()
    cov_matrix = returns.cov()
    
    results = []
    
    for _ in range(n_simulations):
        # Generate random weights
        weights = np.random.random(len(mean_returns))
        weights /= weights.sum()
        
        # Calculate portfolio statistics
        port_return = np.sum(mean_returns * weights) * TRADING_DAYS
        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(TRADING_DAYS)
        sharpe_ratio = (port_return - DEFAULT_RF_ANNUAL) / port_vol if port_vol > 0 else 0
        
        results.append({
            'weights': weights,
            'return': port_return,
            'volatility': port_vol,
            'sharpe': sharpe_ratio
        })
    
    return pd.DataFrame(results)

# -------------------------------------------------------------
# ADVANCED VISUALIZATION FUNCTIONS
# -------------------------------------------------------------
def create_3d_efficient_frontier(returns: pd.DataFrame, risk_free_rate: float = 0.03) -> go.Figure:
    """Create 3D efficient frontier visualization"""
    
    # Calculate covariance matrix and returns
    cov_matrix = returns.cov()
    mu = returns.mean() * TRADING_DAYS
    
    # Generate random portfolios for 3D visualization
    n_portfolios = 1000
    n_assets = len(returns.columns)
    
    returns_3d, volatilities_3d, sharpes_3d = [], [], []
    
    for _ in range(n_portfolios):
        weights = np.random.random(n_assets)
        weights /= weights.sum()
        
        port_return = np.sum(mu * weights)
        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(TRADING_DAYS)
        sharpe = (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0
        
        returns_3d.append(port_return)
        volatilities_3d.append(port_vol)
        sharpes_3d.append(sharpe)
    
    # Create 3D scatter plot
    fig = go.Figure(data=[
        go.Scatter3d(
            x=volatilities_3d,
            y=returns_3d,
            z=sharpes_3d,
            mode='markers',
            marker=dict(
                size=5,
                color=sharpes_3d,
                colorscale='Viridis',
                opacity=0.8,
                colorbar=dict(title="Sharpe Ratio")
            ),
            hovertemplate='<b>Volatility:</b> %{x:.3f}<br>' +
                         '<b>Return:</b> %{y:.3f}<br>' +
                         '<b>Sharpe:</b> %{z:.3f}<br>'
        )
    ])
    
    fig.update_layout(
        title='3D Portfolio Optimization Space',
        scene=dict(
            xaxis_title='Volatility',
            yaxis_title='Expected Return',
            zaxis_title='Sharpe Ratio',
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.5)
            )
        ),
        height=700,
        showlegend=False
    )
    
    return fig

def create_interactive_3d_risk_surface(returns: pd.DataFrame, weights: pd.Series) -> go.Figure:
    """Create interactive 3D risk surface visualization"""
    
    n_points = 50
    # Create grid of weights for two assets (for 3D surface)
    if len(returns.columns) >= 2:
        asset1, asset2 = returns.columns[0], returns.columns[1]
        
        w1_range = np.linspace(0, 1, n_points)
        w2_range = 1 - w1_range
        
        returns_grid, volatilities_grid, sharpes_grid = [], [], []
        
        for w1 in w1_range:
            w2 = 1 - w1
            temp_weights = pd.Series([w1, w2], index=[asset1, asset2])
            temp_returns = returns[[asset1, asset2]]
            
            metrics = calculate_portfolio_metrics(temp_returns, temp_weights)
            
            returns_grid.append(metrics.expected_return)
            volatilities_grid.append(metrics.expected_volatility)
            sharpes_grid.append(metrics.sharpe_ratio)
        
        # Create 3D surface
        fig = go.Figure(data=[
            go.Scatter3d(
                x=w1_range,
                y=volatilities_grid,
                z=returns_grid,
                mode='lines',
                line=dict(color=sharpes_grid, colorscale='Viridis', width=4),
                hovertemplate='<b>Weight {asset1}:</b> %{x:.2%}<br>' +
                             '<b>Volatility:</b> %{y:.3f}<br>' +
                             '<b>Return:</b> %{z:.3f}<br>'
            )
        ])
        
        # Add current portfolio point
        current_metrics = calculate_portfolio_metrics(returns[[asset1, asset2]], 
                                                     weights[[asset1, asset2]])
        fig.add_trace(go.Scatter3d(
            x=[weights[asset1]],
            y=[current_metrics.expected_volatility],
            z=[current_metrics.expected_return],
            mode='markers',
            marker=dict(size=10, color='red'),
            name='Current Portfolio'
        ))
        
        fig.update_layout(
            title=f'3D Risk-Return Surface: {asset1} vs {asset2}',
            scene=dict(
                xaxis_title=f'{asset1} Weight',
                yaxis_title='Volatility',
                zaxis_title='Expected Return',
                camera=dict(
                    eye=dict(x=1.5, y=1.5, z=1.5)
                )
            ),
            height=700
        )
        
        return fig
    else:
        # Fallback to 2D if not enough assets
        fig = go.Figure()
        fig.update_layout(title="Need at least 2 assets for 3D surface")
        return fig

def create_risk_contribution_3d(returns: pd.DataFrame, weights: pd.Series) -> go.Figure:
    """Create 3D risk contribution visualization"""
    
    # Calculate risk contributions
    cov_matrix = returns.cov()
    portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol if portfolio_vol > 0 else np.zeros_like(weights)
    risk_contributions = weights * marginal_contrib
    percent_contributions = risk_contributions / risk_contributions.sum()
    
    # Create 3D bar chart
    assets = returns.columns.tolist()
    x_pos = list(range(len(assets)))
    
    fig = go.Figure(data=[
        go.Bar3d(
            x=x_pos,
            y=[0] * len(assets),  # All at y=0 for single series
            z=[0] * len(assets),  # All at z=0 base
            dx=[0.8] * len(assets),
            dy=[0.8] * len(assets),
            dz=weights.values * 100,  # Height based on weight
            text=[f"{asset}<br>Weight: {w:.1%}<br>Risk: {r:.1%}" 
                  for asset, w, r in zip(assets, weights.values, percent_contributions)],
            hovertemplate='<b>%{text}</b><extra></extra>',
            marker=dict(
                color=percent_contributions * 100,
                colorscale='RdYlGn_r',
                colorbar=dict(title="Risk Contribution %")
            )
        )
    ])
    
    fig.update_layout(
        title='3D Portfolio Weights and Risk Contributions',
        scene=dict(
            xaxis=dict(title='Assets', ticktext=assets, tickvals=x_pos),
            yaxis=dict(title='', showticklabels=False),
            zaxis=dict(title='Portfolio Weight (%)'),
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.2)
            )
        ),
        height=700
    )
    
    return fig

def create_correlation_heatmap_3d(returns: pd.DataFrame) -> go.Figure:
    """Create 3D correlation matrix visualization"""
    
    corr_matrix = returns.corr()
    assets = corr_matrix.columns.tolist()
    
    # Prepare data for 3D surface
    x = list(range(len(assets)))
    y = list(range(len(assets)))
    X, Y = np.meshgrid(x, y)
    Z = corr_matrix.values
    
    fig = go.Figure(data=[
        go.Surface(
            z=Z,
            x=X,
            y=Y,
            colorscale='RdBu',
            colorbar=dict(title="Correlation"),
            contours=dict(
                z=dict(show=True, usecolormap=True, highlightcolor="limegreen", project=dict(z=True))
            )
        )
    ])
    
    fig.update_layout(
        title='3D Correlation Matrix Surface',
        scene=dict(
            xaxis=dict(title='Assets', ticktext=assets, tickvals=x),
            yaxis=dict(title='Assets', ticktext=assets, tickvals=y),
            zaxis=dict(title='Correlation', range=[-1, 1]),
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.2)
            )
        ),
        height=700
    )
    
    return fig

def create_time_series_3d(prices: pd.DataFrame) -> go.Figure:
    """Create 3D time series visualization"""
    
    # Normalize prices for better visualization
    normalized_prices = prices / prices.iloc[0]
    
    # Prepare data for 3D line plot
    dates = pd.to_datetime(normalized_prices.index)
    assets = normalized_prices.columns.tolist()
    
    fig = go.Figure()
    
    for i, asset in enumerate(assets):
        fig.add_trace(go.Scatter3d(
            x=[i] * len(dates),
            y=dates,
            z=normalized_prices[asset].values,
            mode='lines',
            name=asset,
            line=dict(width=2),
            hovertemplate=f'<b>{asset}</b><br>Date: %{{y|%Y-%m-%d}}<br>Price: %{{z:.2f}}<extra></extra>'
        ))
    
    fig.update_layout(
        title='3D Asset Price Time Series',
        scene=dict(
            xaxis=dict(title='Assets', ticktext=assets, tickvals=list(range(len(assets)))),
            yaxis=dict(title='Date'),
            zaxis=dict(title='Normalized Price'),
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.2)
            )
        ),
        height=700,
        showlegend=True
    )
    
    return fig

# -------------------------------------------------------------
# COMPREHENSIVE METRICS DISPLAY FUNCTIONS
# -------------------------------------------------------------
def display_performance_metrics_tab(metrics: PortfolioMetrics, risk_free_rate: float):
    """Display comprehensive performance metrics"""
    
    st.markdown("### üìä Performance Metrics")
    
    # Create columns for different metric categories
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üìà Return Metrics")
        st.metric("Expected Annual Return", f"{metrics.expected_return:.2%}")
        st.metric("Cumulative Return", f"{metrics.cumulative_return:.2%}")
        st.metric("Annual Volatility", f"{metrics.expected_volatility:.2%}")
        st.metric("Downside Deviation", f"{metrics.downside_deviation:.2%}")
    
    with col2:
        st.markdown("#### ‚öñÔ∏è Risk-Adjusted Returns")
        st.metric("Sharpe Ratio", f"{metrics.sharpe_ratio:.3f}")
        st.metric("Sortino Ratio", f"{metrics.sortino_ratio:.3f}")
        st.metric("Calmar Ratio", f"{metrics.calmar_ratio:.3f}")
        st.metric("Omega Ratio", f"{metrics.omega_ratio:.3f}")
    
    with col3:
        st.markdown("#### üìâ Risk Metrics")
        st.metric("Maximum Drawdown", f"{metrics.max_drawdown:.2%}")
        st.metric("VaR (95%)", f"{metrics.var_95:.2%}")
        st.metric("CVaR (95%)", f"{metrics.cvar_95:.2%}")
        st.metric("Ulcer Index", f"{metrics.ulcer_index:.2f}")
    
    # Additional metrics in expanders
    with st.expander("üìã Advanced Performance Metrics", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Tail Ratio", f"{metrics.tail_ratio:.3f}")
            st.metric("Gain to Pain Ratio", f"{metrics.gain_to_pain_ratio:.3f}")
            st.metric("Recovery Factor", f"{metrics.recovery_factor:.3f}")
            st.metric("Average Drawdown", f"{metrics.avg_drawdown:.2%}")
        
        with col2:
            st.metric("Skewness", f"{metrics.skewness:.3f}")
            st.metric("Excess Kurtosis", f"{metrics.kurtosis:.3f}")
            st.metric("M¬≤ Ratio", f"{metrics.m2_ratio:.3f}")
            st.metric("M¬≥ Ratio", f"{metrics.m3_ratio:.3f}")
        
        with col3:
            st.metric("Max DD Duration", f"{metrics.max_drawdown_duration} days")
            st.metric("Information Ratio", f"{metrics.information_ratio:.3f}")
            st.metric("Tracking Error", f"{metrics.tracking_error:.2%}")
            st.metric("Beta", f"{metrics.beta:.3f}")
    
    # Performance visualization
    st.markdown("### üìä Performance Distribution")
    
    # Create synthetic returns for visualization
    np.random.seed(42)
    synthetic_returns = np.random.normal(
        metrics.expected_return / TRADING_DAYS,
        metrics.expected_volatility / np.sqrt(TRADING_DAYS),
        1000
    )
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Return Distribution', 'Cumulative Returns', 
                       'Drawdown Analysis', 'QQ Plot'),
        specs=[[{'type': 'histogram'}, {'type': 'scatter'}],
               [{'type': 'scatter'}, {'type': 'scatter'}]]
    )
    
    # Histogram of returns
    fig.add_trace(
        go.Histogram(x=synthetic_returns * 100, nbinsx=50, name='Returns'),
        row=1, col=1
    )
    
    # Add normal distribution overlay
    x_norm = np.linspace(synthetic_returns.min(), synthetic_returns.max(), 100)
    y_norm = norm.pdf(x_norm, synthetic_returns.mean(), synthetic_returns.std())
    fig.add_trace(
        go.Scatter(x=x_norm * 100, y=y_norm, mode='lines', name='Normal Dist', line=dict(color='red')),
        row=1, col=1
    )
    
    # Cumulative returns simulation
    cumulative_sim = (1 + synthetic_returns).cumprod()
    fig.add_trace(
        go.Scatter(y=(cumulative_sim - 1) * 100, mode='lines', name='Cumulative Return'),
        row=1, col=2
    )
    
    # Drawdown analysis
    running_max = cumulative_sim.expanding().max()
    drawdown_sim = (cumulative_sim - running_max) / running_max * 100
    fig.add_trace(
        go.Scatter(y=drawdown_sim, mode='lines', name='Drawdown', fill='tozeroy'),
        row=2, col=1
    )
    
    # QQ plot
    theoretical_quantiles = norm.ppf(np.linspace(0.01, 0.99, len(synthetic_returns)))
    sorted_returns = np.sort(synthetic_returns)
    fig.add_trace(
        go.Scatter(x=theoretical_quantiles, y=sorted_returns, mode='markers', name='QQ Plot'),
        row=2, col=2
    )
    
    # Add 45-degree line for QQ plot
    min_val = min(theoretical_quantiles.min(), sorted_returns.min())
    max_val = max(theoretical_quantiles.max(), sorted_returns.max())
    fig.add_trace(
        go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', 
                  name='45¬∞ Line', line=dict(dash='dash', color='red')),
        row=2, col=2
    )
    
    fig.update_layout(height=800, showlegend=True)
    st.plotly_chart(fig, use_container_width=True)

def display_risk_metrics_tab(returns: pd.DataFrame, weights: pd.Series, metrics: PortfolioMetrics):
    """Display comprehensive risk metrics and analysis"""
    
    st.markdown("### ‚ö†Ô∏è Comprehensive Risk Analysis")
    
    # Calculate additional risk metrics
    portfolio_returns = (returns * weights).sum(axis=1)
    
    # Calculate Value at Risk using different methods
    var_historical = np.percentile(portfolio_returns, 5) * np.sqrt(TRADING_DAYS)
    var_parametric = norm.ppf(0.05, portfolio_returns.mean(), portfolio_returns.std()) * np.sqrt(TRADING_DAYS)
    
    # Calculate Expected Shortfall/CVaR
    cvar_historical = portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)].mean() * np.sqrt(TRADING_DAYS)
    
    # Calculate stress test scenarios
    stress_scenarios = {
        "Market Crash (-10%)": -0.10 / np.sqrt(TRADING_DAYS),
        "Major Correction (-5%)": -0.05 / np.sqrt(TRADING_DAYS),
        "Volatility Spike": portfolio_returns.std() * 2,
        "Liquidity Crunch": portfolio_returns.std() * 1.5
    }
    
    # Display risk metrics in columns
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üìâ Downside Risk")
        st.metric("Maximum Drawdown", f"{metrics.max_drawdown:.2%}")
        st.metric("Average Drawdown", f"{metrics.avg_drawdown:.2%}")
        st.metric("Ulcer Index", f"{metrics.ulcer_index:.2f}")
        st.metric("Downside Deviation", f"{metrics.downside_deviation:.2%}")
    
    with col2:
        st.markdown("#### üí∞ Value at Risk")
        st.metric("Historical VaR (95%)", f"{var_historical:.2%}")
        st.metric("Parametric VaR (95%)", f"{var_parametric:.2%}")
        st.metric("Conditional VaR (95%)", f"{cvar_historical:.2%}")
        st.metric("Tail Ratio", f"{metrics.tail_ratio:.3f}")
    
    with col3:
        st.markdown("#### üìä Distribution Metrics")
        st.metric("Skewness", f"{metrics.skewness:.3f}")
        st.metric("Excess Kurtosis", f"{metrics.kurtosis:.3f}")
        st.metric("Omega Ratio", f"{metrics.omega_ratio:.3f}")
        st.metric("Gain to Pain Ratio", f"{metrics.gain_to_pain_ratio:.3f}")
    
    # Stress Testing Section
    st.markdown("### üß™ Stress Testing Scenarios")
    
    # Create gauge charts for stress scenarios
    fig_stress = make_subplots(
        rows=1, cols=len(stress_scenarios),
        subplot_titles=list(stress_scenarios.keys()),
        specs=[[{'type': 'indicator'}] * len(stress_scenarios)]
    )
    
    for i, (scenario, impact) in enumerate(stress_scenarios.items(), 1):
        impact_pct = abs(impact * np.sqrt(TRADING_DAYS) * 100)
        fig_stress.add_trace(
            go.Indicator(
                mode="gauge+number",
                value=impact_pct,
                title={'text': f"{impact_pct:.1f}%"},
                gauge={
                    'axis': {'range': [0, 20]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 5], 'color': "green"},
                        {'range': [5, 10], 'color': "yellow"},
                        {'range': [10, 15], 'color': "orange"},
                        {'range': [15, 20], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': impact_pct
                    }
                }
            ),
            row=1, col=i
        )
    
    fig_stress.update_layout(height=300)
    st.plotly_chart(fig_stress, use_container_width=True)
    
    # Risk Decomposition
    st.markdown("### üéØ Risk Decomposition")
    
    # Calculate risk contributions
    cov_matrix = returns.cov()
    portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol if portfolio_vol > 0 else np.zeros_like(weights)
    risk_contributions = weights * marginal_contrib
    percent_contributions = risk_contributions / risk_contributions.sum()
    
    # Create risk contribution visualization
    fig_risk = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Risk Contribution by Asset', 'Risk vs Return Contribution'),
        specs=[[{'type': 'pie'}, {'type': 'scatter'}]]
    )
    
    # Pie chart for risk contributions
    fig_risk.add_trace(
        go.Pie(
            labels=percent_contributions.index,
            values=percent_contributions.values * 100,
            hole=0.4,
            textinfo='label+percent',
            marker=dict(colors=px.colors.qualitative.Set3)
        ),
        row=1, col=1
    )
    
    # Scatter plot of weight vs risk contribution
    fig_risk.add_trace(
        go.Scatter(
            x=weights.values * 100,
            y=percent_contributions.values * 100,
            mode='markers+text',
            marker=dict(size=weights.values * 100, color=percent_contributions.values * 100,
                       colorscale='RdYlGn_r', showscale=True, colorbar=dict(title="Risk %")),
            text=weights.index,
            textposition="top center",
            hovertemplate='<b>%{text}</b><br>Weight: %{x:.1f}%<br>Risk Contribution: %{y:.1f}%<extra></extra>'
        ),
        row=1, col=2
    )
    
    fig_risk.update_xaxes(title_text="Portfolio Weight (%)", row=1, col=2)
    fig_risk.update_yaxes(title_text="Risk Contribution (%)", row=1, col=2)
    fig_risk.update_layout(height=500)
    st.plotly_chart(fig_risk, use_container_width=True)
    
    # Correlation Analysis
    st.markdown("### üîó Correlation Analysis")
    
    corr_matrix = returns.corr()
    
    fig_corr = go.Figure(data=[
        go.Heatmap(
            z=corr_matrix.values,
            x=corr_matrix.columns,
            y=corr_matrix.columns,
            colorscale='RdBu',
            zmid=0,
            text=np.round(corr_matrix.values, 2),
            texttemplate='%{text}',
            textfont={"size": 10},
            colorbar=dict(title="Correlation")
        )
    ])
    
    fig_corr.update_layout(
        title="Asset Correlation Matrix",
        height=600
    )
    st.plotly_chart(fig_corr, use_container_width=True)
    
    # Rolling Risk Metrics
    st.markdown("### üìà Rolling Risk Metrics")
    
    # Calculate rolling metrics
    window = min(60, len(portfolio_returns))
    rolling_vol = portfolio_returns.rolling(window=window).std() * np.sqrt(TRADING_DAYS)
    rolling_var = portfolio_returns.rolling(window=window).apply(
        lambda x: np.percentile(x, 5)) * np.sqrt(TRADING_DAYS)
    
    fig_rolling = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility', 'Rolling Value at Risk (95%)'),
        shared_xaxes=True
    )
    
    fig_rolling.add_trace(
        go.Scatter(x=returns.index, y=rolling_vol * 100, mode='lines', name='Volatility',
                  line=dict(color='blue')),
        row=1, col=1
    )
    
    fig_rolling.add_trace(
        go.Scatter(x=returns.index, y=rolling_var * 100, mode='lines', name='VaR',
                  line=dict(color='red'), fill='tozeroy'),
        row=2, col=1
    )
    
    fig_rolling.update_yaxes(title_text="Volatility (%)", row=1, col=1)
    fig_rolling.update_yaxes(title_text="VaR (%)", row=2, col=1)
    fig_rolling.update_xaxes(title_text="Date", row=2, col=1)
    fig_rolling.update_layout(height=600, showlegend=True)
    st.plotly_chart(fig_rolling, use_container_width=True)

# -------------------------------------------------------------
# MAIN APPLICATION LAYOUT AND LOGIC
# -------------------------------------------------------------
def main():
    """Main application function"""
    
    # Display title and header
    st.title(APP_TITLE)
    
    # About section
    with st.expander("üìñ **About Apollo/ENIGMA Terminal v6.0**", expanded=False):
        st.markdown("""
        ### Institutional-Grade Portfolio Analytics Platform
        
        **Key Features:**
        - **Global Multi-Asset Optimization**: 1500+ assets across 15 categories
        - **Advanced 3D Visualization**: Interactive 3D charts for portfolio analysis
        - **Comprehensive Risk Metrics**: 50+ risk and performance metrics
        - **Institutional Strategies**: 12+ portfolio optimization methodologies
        - **Real-Time Analytics**: Parallel data loading with intelligent caching
        - **Professional Reporting**: Export capabilities and detailed analysis
        
        **Version:** 6.0 | **Last Updated:** """ + datetime.now().strftime("%Y-%m-%d") + """ | 
        **Cache Status:** """ + str(EnhancedCache.get_cache_stats()['total_files']) + " files")
    
    # Initialize session state
    if 'portfolio_data' not in st.session_state:
        st.session_state.portfolio_data = None
    if 'optimization_results' not in st.session_state:
        st.session_state.optimization_results = None
    if 'selected_tickers' not in st.session_state:
        st.session_state.selected_tickers = []
    if 'metrics_data' not in st.session_state:
        st.session_state.metrics_data = None
    
    # Create sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuration")
        
        # Date range selection
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input(
                "Start Date",
                value=datetime.now() - timedelta(days=365*3),
                max_value=datetime.now() - timedelta(days=1),
                help="Start date for historical data"
            )
        with col2:
            end_date = st.date_input(
                "End Date",
                value=datetime.now(),
                max_value=datetime.now(),
                help="End date for historical data"
            )
        
        # Asset selection
        st.markdown("### üìä Asset Selection")
        
        # Quick selection buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Select Tech", use_container_width=True):
                st.session_state.selected_tickers = GLOBAL_ASSET_UNIVERSE["US_Tech_Stocks"][:10]
        with col2:
            if st.button("Select Diversified", use_container_width=True):
                st.session_state.selected_tickers = ["SPY", "TLT", "GLD", "VNQ", "BTC-USD"]
        
        # Category selection
        asset_category = st.selectbox(
            "Asset Category",
            list(GLOBAL_ASSET_UNIVERSE.keys()),
            help="Select asset category to filter tickers"
        )
        
        # Multi-select for tickers
        selected_tickers = st.multiselect(
            "Select Assets",
            options=GLOBAL_ASSET_UNIVERSE[asset_category],
            default=st.session_state.selected_tickers or GLOBAL_ASSET_UNIVERSE[asset_category][:5],
            help="Select assets for portfolio construction",
            key="asset_multiselect"
        )
        
        st.session_state.selected_tickers = selected_tickers
        
        # Optimization parameters
        st.markdown("### ‚öñÔ∏è Optimization Parameters")
        
        risk_free_rate = st.slider(
            "Risk-Free Rate (%)",
            min_value=0.0,
            max_value=10.0,
            value=2.5,
            step=0.1,
            help="Annual risk-free rate for Sharpe ratio calculation"
        ) / 100
        
        # Strategy selection with parameters - FIXED: Move this before using it
        strategy_options = list(PORTFOLIO_STRATEGIES.keys())
        strategy = st.selectbox(
            "Portfolio Strategy",
            options=strategy_options,
            help="Select portfolio optimization strategy"
        )
        
        # Strategy-specific parameters
        if strategy in PORTFOLIO_STRATEGIES:
            strategy_params = PORTFOLIO_STRATEGIES[strategy]["parameters"]
            kwargs = {}
            
            for param_name, param_config in strategy_params.items():
                param_type = param_config.get("type", "float")
                
                if param_type == "float":
                    default_val = param_config.get("default", 0.0)
                    min_val = param_config.get("min", 0.0)
                    max_val = param_config.get("max", 1.0)
                    
                    kwargs[param_name] = st.slider(
                        f"{param_name.replace('_', ' ').title()}",
                        min_value=min_val,
                        max_value=max_val,
                        value=default_val,
                        step=(max_val - min_val) / 100
                    )
                
                elif param_type == "bool":
                    kwargs[param_name] = st.checkbox(
                        f"{param_name.replace('_', ' ').title()}",
                        value=param_config.get("default", False)
                    )
                
                elif param_type == "select":
                    options = param_config.get("options", [])
                    default = param_config.get("default", "")
                    default_index = options.index(default) if default in options else 0
                    kwargs[param_name] = st.selectbox(
                        f"{param_name.replace('_', ' ').title()}",
                        options=options,
                        index=default_index
                    )
                
                elif param_type == "str":
                    kwargs[param_name] = st.text_input(
                        f"{param_name.replace('_', ' ').title()}",
                        value=param_config.get("default", "")
                    )
                
                elif param_type == "dict":
                    # For custom weights, we'll handle this separately
                    if param_name == "weights":
                        st.info("Custom weights will be entered after asset selection")
        
        # Advanced settings
        with st.expander("‚ö° Advanced Settings", expanded=False):
            monte_carlo_sims = st.slider(
                "Monte Carlo Simulations",
                min_value=1000,
                max_value=50000,
                value=10000,
                step=1000
            )
            
            cache_ttl = st.slider(
                "Cache TTL (hours)",
                min_value=1,
                max_value=24,
                value=6,
                step=1
            )
            
            use_parallel = st.checkbox("Use Parallel Download", value=True)
        
        # Action buttons
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üöÄ Run Analysis", use_container_width=True, type="primary"):
                if not selected_tickers:
                    st.error("Please select at least one asset")
                    return
                
                with st.spinner("Loading market data and optimizing portfolio..."):
                    # Load prices
                    prices = load_global_prices_enhanced(
                        selected_tickers,
                        str(start_date),
                        str(end_date),
                        use_parallel=use_parallel
                    )
                    
                    if not prices.empty:
                        st.session_state.portfolio_data = prices
                        
                        # Calculate returns
                        returns = prices.pct_change().dropna()
                        
                        # Run optimization
                        try:
                            result = optimize_portfolio_strategy(
                                returns, 
                                strategy, 
                                risk_free_rate,
                                **kwargs
                            )
                            
                            if result:
                                st.session_state.optimization_results = result
                                st.success(f"‚úÖ Optimization completed using {strategy} strategy!")
                            else:
                                st.error("Optimization failed. Please try different parameters.")
                        except Exception as e:
                            st.error(f"Optimization error: {str(e)}")
        
        with col2:
            if st.button("üîÑ Clear Cache", use_container_width=True):
                EnhancedCache.clear_cache()
                st.success("Cache cleared successfully!")
                st.rerun()
        
        with col3:
            if st.button("üìä View Cache Stats", use_container_width=True):
                stats = EnhancedCache.get_cache_stats()
                st.info(f"""
                **Cache Statistics:**
                - Files: {stats['total_files']}
                - Size: {stats['total_size_mb']} MB
                - Directory: {stats['cache_dir']}
                """)
        
        # Display current status
        st.markdown("---")
        if st.session_state.portfolio_data is not None:
            st.success(f"‚úÖ Loaded {len(st.session_state.portfolio_data.columns)} assets")
        else:
            st.info("üëà Configure settings and click 'Run Analysis'")
    
    # Main content area
    if st.session_state.portfolio_data is not None and st.session_state.optimization_results is not None:
        display_main_analysis(
            st.session_state.portfolio_data,
            st.session_state.optimization_results,
            risk_free_rate,
            monte_carlo_sims
        )
    else:
        display_welcome_screen()

def display_main_analysis(prices: pd.DataFrame, results: OptimizationResult, 
                         risk_free_rate: float, monte_carlo_sims: int):
    """Display main analysis dashboard"""
    
    # Create tabs for different analysis sections
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà Overview", 
        "‚öñÔ∏è Optimization", 
        "üìä Performance",
        "üìâ Risk Analysis",
        "üéØ 3D Visualization",
        "üìã Report"
    ])
    
    with tab1:
        display_portfolio_overview(prices, results)
    
    with tab2:
        display_optimization_results(results, prices, risk_free_rate)
    
    with tab3:
        display_performance_metrics_tab(results.metrics, risk_free_rate)
    
    with tab4:
        returns = prices.pct_change().dropna()
        display_risk_metrics_tab(returns, results.weights, results.metrics)
    
    with tab5:
        display_3d_visualization_tab(prices, results)
    
    with tab6:
        generate_comprehensive_report(prices, results, risk_free_rate)

def display_portfolio_overview(prices: pd.DataFrame, results: OptimizationResult):
    """Display portfolio overview dashboard"""
    
    st.markdown("## üìà Portfolio Overview")
    
    # Key metrics in columns
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Expected Return", 
            f"{results.metrics.expected_return:.2%}",
            help="Annualized expected portfolio return"
        )
    
    with col2:
        st.metric(
            "Expected Volatility",
            f"{results.metrics.expected_volatility:.2%}",
            help="Annualized portfolio volatility"
        )
    
    with col3:
        st.metric(
            "Sharpe Ratio",
            f"{results.metrics.sharpe_ratio:.3f}",
            help="Risk-adjusted return ratio"
        )
    
    with col4:
        st.metric(
            "Max Drawdown",
            f"{results.metrics.max_drawdown:.2%}",
            delta_color="inverse",
            help="Maximum historical drawdown"
        )
    
    # Portfolio composition
    st.markdown("### üéØ Portfolio Composition")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Pie chart of weights
        weights_df = pd.DataFrame({
            'Asset': results.weights.index,
            'Weight': results.weights.values,
            'Color': px.colors.qualitative.Set3[:len(results.weights)]
        })
        
        fig_pie = px.pie(
            weights_df,
            values='Weight',
            names='Asset',
            title='Portfolio Weights',
            color='Asset',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig_pie.update_traces(textposition='inside', textinfo='percent+label')
        fig_pie.update_layout(height=400)
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        # Weights table
        st.markdown("#### Weight Allocation")
        weights_table = pd.DataFrame({
            'Asset': results.weights.index,
            'Weight': results.weights.values,
            '%': (results.weights.values * 100).round(2)
        }).sort_values('Weight', ascending=False)
        
        # Format for display
        display_table = weights_table.copy()
        display_table['Weight'] = display_table['Weight'].apply(lambda x: f"{x:.2%}")
        display_table['%'] = display_table['%'].apply(lambda x: f"{x}%")
        
        st.dataframe(
            display_table,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Asset": st.column_config.TextColumn("Asset"),
                "Weight": st.column_config.TextColumn("Weight"),
                "%": st.column_config.TextColumn("%")
            }
        )
        
        # Summary stats
        st.metric("Number of Assets", len(results.weights))
        st.metric("Top 3 Concentration", 
                 f"{(results.weights.nlargest(3).sum() * 100):.1f}%")
    
    # Price performance
    st.markdown("### üìä Asset Performance")
    
    # Normalize prices for comparison
    normalized_prices = prices / prices.iloc[0]
    
    fig_prices = px.line(
        normalized_prices,
        title='Normalized Price Performance (Rebased to 1)',
        labels={'value': 'Normalized Price', 'variable': 'Asset'}
    )
    fig_prices.update_layout(height=500, hovermode='x unified')
    st.plotly_chart(fig_prices, use_container_width=True)
    
    # Correlation heatmap
    st.markdown("### üîó Asset Correlations")
    
    returns = prices.pct_change().dropna()
    corr_matrix = returns.corr()
    
    fig_corr = px.imshow(
        corr_matrix,
        text_auto='.2f',
        aspect='auto',
        color_continuous_scale='RdBu',
        title='Correlation Matrix',
        labels=dict(color="Correlation")
    )
    fig_corr.update_layout(height=600)
    st.plotly_chart(fig_corr, use_container_width=True)

def display_optimization_results(results: OptimizationResult, prices: pd.DataFrame, risk_free_rate: float):
    """Display optimization results"""
    
    st.markdown("## ‚öñÔ∏è Portfolio Optimization")
    
    # Strategy information
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown(f"### Strategy: **{results.strategy}**")
        st.markdown(PORTFOLIO_STRATEGIES.get(results.strategy, {}).get("description", ""))
    
    with col2:
        st.metric("Optimization Status", "‚úÖ Complete")
    
    # Efficient frontier visualization
    st.markdown("### üìà Efficient Frontier")
    
    if results.efficient_frontier is not None:
        fig_ef = go.Figure()
        
        # Add efficient frontier
        fig_ef.add_trace(go.Scatter(
            x=results.efficient_frontier['Volatility'],
            y=results.efficient_frontier['Return'],
            mode='lines',
            name='Efficient Frontier',
            line=dict(color='blue', width=2),
            hovertemplate='Volatility: %{x:.3f}<br>Return: %{y:.3f}<extra></extra>'
        ))
        
        # Add optimal portfolio
        fig_ef.add_trace(go.Scatter(
            x=[results.expected_volatility],
            y=[results.expected_return],
            mode='markers',
            name='Optimal Portfolio',
            marker=dict(size=15, color='red'),
            hovertemplate=f'<b>Optimal Portfolio</b><br>'
                         f'Volatility: {results.expected_volatility:.3f}<br>'
                         f'Return: {results.expected_return:.3f}<br>'
                         f'Sharpe: {results.sharpe_ratio:.3f}<extra></extra>'
        ))
        
        # Add risk-free rate line
        x_range = np.linspace(0, results.efficient_frontier['Volatility'].max() * 1.1, 100)
        fig_ef.add_trace(go.Scatter(
            x=x_range,
            y=risk_free_rate + (results.metrics.sharpe_ratio * x_range),
            mode='lines',
            name='Capital Market Line',
            line=dict(color='green', dash='dash'),
            hovertemplate='CML<br>Return: %{y:.3f}<extra></extra>'
        ))
        
        fig_ef.update_layout(
            title='Efficient Frontier with Capital Market Line',
            xaxis_title='Volatility',
            yaxis_title='Expected Return',
            height=600,
            showlegend=True,
            hovermode='closest'
        )
        
        st.plotly_chart(fig_ef, use_container_width=True)
    
    # Monte Carlo simulation
    st.markdown("### üé≤ Monte Carlo Simulation")
    
    returns = prices.pct_change().dropna()
    monte_carlo_results = run_monte_carlo_simulation(returns, n_simulations=5000)
    
    if not monte_carlo_results.empty:
        fig_mc = px.scatter(
            monte_carlo_results,
            x='volatility',
            y='return',
            color='sharpe',
            color_continuous_scale='Viridis',
            labels={
                'volatility': 'Volatility',
                'return': 'Expected Return',
                'sharpe': 'Sharpe Ratio'
            },
            title='Monte Carlo Simulation: Random Portfolios'
        )
        
        # Add optimal portfolio point
        fig_mc.add_trace(go.Scatter(
            x=[results.expected_volatility],
            y=[results.expected_return],
            mode='markers',
            marker=dict(size=15, color='red', symbol='star'),
            name='Optimal Portfolio',
            hovertemplate=f'<b>Optimal Portfolio</b><br>'
                         f'Volatility: {results.expected_volatility:.3f}<br>'
                         f'Return: {results.expected_return:.3f}<extra></extra>'
        ))
        
        fig_mc.update_layout(height=500)
        st.plotly_chart(fig_mc, use_container_width=True)
    
    # Risk contribution analysis
    st.markdown("### üéØ Risk Contribution Analysis")
    
    if results.risk_contributions is not None:
        risk_df = pd.DataFrame({
            'Asset': results.risk_contributions.index,
            'Weight': results.weights.values,
            'Risk Contribution': results.risk_contributions.values,
            'Risk %': (results.risk_contributions.values / results.risk_contributions.sum() * 100)
        }).sort_values('Risk %', ascending=False)
        
        fig_risk = make_subplots(
            rows=1, cols=2,
            subplot_titles=('Risk Contribution', 'Weight vs Risk Contribution'),
            specs=[[{'type': 'bar'}, {'type': 'scatter'}]]
        )
        
        # Bar chart for risk contributions
        fig_risk.add_trace(
            go.Bar(
                x=risk_df['Asset'],
                y=risk_df['Risk %'],
                name='Risk Contribution %',
                marker_color='coral'
            ),
            row=1, col=1
        )
        
        # Scatter plot of weight vs risk
        fig_risk.add_trace(
            go.Scatter(
                x=risk_df['Weight'] * 100,
                y=risk_df['Risk %'],
                mode='markers+text',
                marker=dict(size=15, color=risk_df['Risk %'], colorscale='Viridis', showscale=True),
                text=risk_df['Asset'],
                textposition="top center",
                name='Weight vs Risk',
                hovertemplate='<b>%{text}</b><br>Weight: %{x:.1f}%<br>Risk: %{y:.1f}%<extra></extra>'
            ),
            row=1, col=2
        )
        
        fig_risk.update_xaxes(title_text="Asset", row=1, col=1)
        fig_risk.update_yaxes(title_text="Risk Contribution (%)", row=1, col=1)
        fig_risk.update_xaxes(title_text="Portfolio Weight (%)", row=1, col=2)
        fig_risk.update_yaxes(title_text="Risk Contribution (%)", row=1, col=2)
        fig_risk.update_layout(height=500, showlegend=False)
        
        st.plotly_chart(fig_risk, use_container_width=True)
        
        # Display risk parity score
        risk_parity_score = 1 - (risk_df['Risk %'].std() / risk_df['Risk %'].mean())
        st.metric("Risk Parity Score", f"{risk_parity_score:.3f}", 
                 help="1 = Perfect risk parity, 0 = Concentrated risk")

def display_3d_visualization_tab(prices: pd.DataFrame, results: OptimizationResult):
    """Display 3D visualization tab"""
    
    st.markdown("## üéØ 3D Visualization Suite")
    
    # Visualization selection
    viz_options = [
        "3D Efficient Frontier",
        "3D Risk Surface",
        "3D Risk Contributions",
        "3D Correlation Matrix",
        "3D Time Series"
    ]
    
    selected_viz = st.selectbox("Select 3D Visualization", viz_options)
    
    # Sliding parameters for 3D views
    st.markdown("### üéöÔ∏è Visualization Parameters")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        rotation_x = st.slider("Rotation X", 0, 360, 30, key="rot_x")
    with col2:
        rotation_y = st.slider("Rotation Y", 0, 360, 30, key="rot_y")
    with col3:
        rotation_z = st.slider("Rotation Z", 0, 360, 30, key="rot_z")
    
    # Generate selected visualization
    returns = prices.pct_change().dropna()
    
    if selected_viz == "3D Efficient Frontier":
        fig = create_3d_efficient_frontier(returns)
        
    elif selected_viz == "3D Risk Surface":
        fig = create_interactive_3d_risk_surface(returns, results.weights)
        
    elif selected_viz == "3D Risk Contributions":
        fig = create_risk_contribution_3d(returns, results.weights)
        
    elif selected_viz == "3D Correlation Matrix":
        fig = create_correlation_heatmap_3d(returns)
        
    elif selected_viz == "3D Time Series":
        fig = create_time_series_3d(prices)
    else:
        # Default to efficient frontier if something goes wrong
        fig = create_3d_efficient_frontier(returns)
    
    # Update camera position based on sliders
    if fig is not None:
        fig.update_layout(
            scene_camera=dict(
                eye=dict(x=np.cos(np.radians(rotation_x)), 
                        y=np.sin(np.radians(rotation_y)), 
                        z=np.sin(np.radians(rotation_z)) * 2)
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Additional 3D insights
        st.markdown("### üìä 3D Analysis Insights")
        
        if selected_viz == "3D Efficient Frontier":
            st.info("""
            **Insights:**
            - The 3D efficient frontier shows the trade-off between risk (volatility), return, and risk-adjusted return (Sharpe ratio)
            - Optimal portfolios lie on the upper surface of the cloud
            - Color intensity indicates Sharpe ratio quality (darker = better)
            """)
        
        elif selected_viz == "3D Risk Surface":
            st.info("""
            **Insights:**
            - Shows how changing weights between two assets affects portfolio risk and return
            - The surface curvature indicates diversification benefits
            - Steeper slopes indicate higher sensitivity to weight changes
            """)
        
        elif selected_viz == "3D Risk Contributions":
            st.info("""
            **Insights:**
            - Bar height represents portfolio weight
            - Bar color represents risk contribution percentage
            - Ideal portfolio has proportional height and color (balanced risk contribution)
            """)
        
        elif selected_viz == "3D Correlation Matrix":
            st.info("""
            **Insights:**
            - Peaks indicate high positive correlation
            - Valleys indicate high negative correlation
            - Flat areas indicate low correlation
            - Diversification benefits come from combining assets in valleys
            """)
        
        elif selected_viz == "3D Time Series":
            st.info("""
            **Insights:**
            - Shows relative performance of assets over time
            - Parallel lines indicate high correlation
            - Diverging lines indicate decorrelation or different return patterns
            - Steeper slopes indicate higher returns
            """)
        
        # Export 3D visualization
        st.markdown("### üíæ Export Options")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì∑ Capture Screenshot", use_container_width=True, key="capture_screenshot"):
                # Convert plot to HTML for download
                html = fig.to_html(include_plotlyjs='cdn')
                st.download_button(
                    label="Download HTML",
                    data=html,
                    file_name=f"3d_visualization_{selected_viz.replace(' ', '_').lower()}.html",
                    mime="text/html",
                    key="download_html"
                )
        
        with col2:
            if st.button("üñºÔ∏è Save as Image", use_container_width=True, key="save_as_image"):
                # Note: In production, you might want to use plotly's orca for image export
                st.info("Image export requires additional setup. Use HTML download for now.")

def generate_comprehensive_report(prices: pd.DataFrame, results: OptimizationResult, risk_free_rate: float):
    """Generate comprehensive portfolio report"""
    
    st.markdown("## üìã Comprehensive Portfolio Report")
    
    # Executive Summary
    st.markdown("### üìù Executive Summary")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Strategy", results.strategy)
    with col2:
        st.metric("Assets", len(results.weights))
    with col3:
        st.metric("Analysis Period", f"{len(prices)} days")
    with col4:
        st.metric("Risk-Free Rate", f"{risk_free_rate:.2%}")
    
    # Detailed metrics table
    st.markdown("### üìä Detailed Metrics")
    
    metrics_dict = asdict(results.metrics)
    metrics_df = pd.DataFrame(
        [(k.replace('_', ' ').title(), f"{v:.4f}" if isinstance(v, float) else str(v)) 
         for k, v in metrics_dict.items()],
        columns=['Metric', 'Value']
    )
    
    st.dataframe(
        metrics_df,
        use_container_width=True,
        hide_index=True
    )
    
    # Portfolio holdings
    st.markdown("### üéØ Portfolio Holdings")
    
    holdings_df = pd.DataFrame({
        'Asset': results.weights.index,
        'Weight': results.weights.values,
        'Allocation %': (results.weights.values * 100).round(2)
    }).sort_values('Weight', ascending=False)
    
    st.dataframe(
        holdings_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "Asset": st.column_config.TextColumn("Asset"),
            "Weight": st.column_config.NumberColumn("Weight", format="%.4f"),
            "Allocation %": st.column_config.NumberColumn("Allocation %", format="%.2f")
        }
    )
    
    # Risk assessment
    st.markdown("### ‚ö†Ô∏è Risk Assessment")
    
    # Calculate risk scores
    risk_score = min(100, max(0, results.metrics.expected_volatility * 500))
    diversification_score = min(100, len(results.weights) * 10)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Overall Risk Score**")
        st.progress(risk_score / 100, text=f"{risk_score:.0f}/100")
    
    with col2:
        st.markdown("**Diversification Score**")
        st.progress(diversification_score / 100, text=f"{diversification_score:.0f}/100")
    
    with col3:
        st.markdown("**Sharpe Quality**")
        sharpe_score = min(100, max(0, results.metrics.sharpe_ratio * 50))
        st.progress(sharpe_score / 100, text=f"{sharpe_score:.0f}/100")
    
    # Recommendations
    st.markdown("### üí° Recommendations")
    
    recommendations = []
    
    if results.metrics.sharpe_ratio < 1:
        recommendations.append("Consider rebalancing to improve risk-adjusted returns")
    
    if results.metrics.max_drawdown > 0.20:
        recommendations.append("Implement downside protection strategies")
    
    if len(results.weights) < 5:
        recommendations.append("Increase diversification by adding more assets")
    
    if results.metrics.expected_volatility > 0.25:
        recommendations.append("Consider reducing portfolio volatility through hedging")
    
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            st.markdown(f"{i}. {rec}")
    else:
        st.success("‚úÖ Portfolio appears well-optimized. No major recommendations at this time.")
    
    # Export options
    st.markdown("### üíæ Export Report")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # JSON export
        report_data = {
            "portfolio": {
                "strategy": results.strategy,
                "weights": results.weights.to_dict(),
                "metrics": metrics_dict
            },
            "analysis": {
                "date_generated": datetime.now().isoformat(),
                "period": f"{prices.index[0].date()} to {prices.index[-1].date()}",
                "risk_free_rate": risk_free_rate
            }
        }
        
        json_str = json.dumps(report_data, indent=2, default=str)
        st.download_button(
            label="üìÑ Download JSON",
            data=json_str,
            file_name=f"portfolio_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key="download_json"
        )
    
    with col2:
        # CSV export for weights
        csv_weights = results.weights.reset_index()
        csv_weights.columns = ['Asset', 'Weight']
        csv_data = csv_weights.to_csv(index=False)
        st.download_button(
            label="üìä Download Weights CSV",
            data=csv_data,
            file_name=f"portfolio_weights_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="download_csv"
        )
    
    with col3:
        # Generate summary text
        summary_text = f"""
        Portfolio Analysis Report
        Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        Strategy: {results.strategy}
        Number of Assets: {len(results.weights)}
        Analysis Period: {len(prices)} trading days
        
        Key Metrics:
        - Expected Return: {results.metrics.expected_return:.2%}
        - Expected Volatility: {results.metrics.expected_volatility:.2%}
        - Sharpe Ratio: {results.metrics.sharpe_ratio:.3f}
        - Maximum Drawdown: {results.metrics.max_drawdown:.2%}
        - Sortino Ratio: {results.metrics.sortino_ratio:.3f}
        
        Top Holdings:
        {results.weights.nlargest(5).to_string()}
        """
        
        st.download_button(
            label="üìù Download Summary",
            data=summary_text,
            file_name=f"portfolio_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain",
            key="download_summary"
        )

def display_welcome_screen():
    """Display welcome screen"""
    
    st.markdown("""
    # üöÄ Welcome to Apollo/ENIGMA Portfolio Terminal
    
    ### Your Institutional-Grade Portfolio Analytics Platform
    
    **Get Started:**
    1. **Select Assets** - Choose from 1500+ global assets across 15 categories
    2. **Configure Parameters** - Set your risk preferences and optimization strategy
    3. **Run Analysis** - Click "Run Analysis" to generate portfolio insights
    4. **Explore Results** - Dive into comprehensive analytics across multiple tabs
    
    ### üìä Available Analysis Tabs:
    
    | Tab | Description |
    |-----|-------------|
    | üìà Overview | Portfolio composition and performance overview |
    | ‚öñÔ∏è Optimization | Efficient frontier and optimization results |
    | üìä Performance | 50+ performance and risk-adjusted metrics |
    | üìâ Risk Analysis | Comprehensive risk assessment and stress testing |
    | üéØ 3D Visualization | Interactive 3D portfolio visualizations |
    | üìã Report | Comprehensive portfolio report and export |
    
    ### üéØ Key Features:
    
    - **Global Asset Universe**: Stocks, ETFs, bonds, commodities, cryptocurrencies
    - **Multiple Optimization Strategies**: 12+ institutional portfolio methodologies
    - **Advanced Risk Analytics**: VaR, CVaR, stress testing, correlation analysis
    - **3D Visualization**: Interactive 3D charts for enhanced insights
    - **Professional Reporting**: Export capabilities for institutional use
    
    ### ‚ö° Quick Start Tips:
    
    1. Start with a **diversified portfolio** (5-10 assets across different categories)
    2. Use **"Select Tech"** or **"Select Diversified"** buttons for quick setups
    3. Experiment with different **optimization strategies** to see their impact
    4. Check the **3D Visualization** tab for interactive portfolio insights
    
    ---
    
    **Ready to begin?** Configure your portfolio in the sidebar and click **"Run Analysis"**!
    """)
    
    # Display sample portfolios
    st.markdown("### üéØ Sample Portfolio Ideas")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **üåé Global 60/40**
        - SPY (40%)
        - TLT (40%)
        - GLD (10%)
        - VNQ (10%)
        *Classic balanced portfolio*
        """)
    
    with col2:
        st.markdown("""
        **üöÄ Tech Growth**
        - AAPL (25%)
        - MSFT (25%)
        - NVDA (20%)
        - GOOGL (15%)
        - AMZN (15%)
        *High-growth technology focus*
        """)
    
    with col3:
        st.markdown("""
        **üõ°Ô∏è Risk-Parity**
        - TLT (30%)
        - GLD (25%)
        - SPY (20%)
        - VNQ (15%)
        - BTC-USD (10%)
        *Diversified risk allocation*
        """)
    
    # Display cache statistics
    cache_stats = EnhancedCache.get_cache_stats()
    st.info(f"""
    **System Status:**
    - Cache: {cache_stats['total_files']} files ({cache_stats['total_size_mb']} MB)
    - Asset Universe: {len(ALL_TICKERS)} assets
    - Optimization Strategies: {len(PORTFOLIO_STRATEGIES)} methods
    """)

# -------------------------------------------------------------
# RUN THE APPLICATION
# -------------------------------------------------------------
if __name__ == "__main__":
    try:
        # Check for required packages
        if not PYPFOPT_AVAILABLE:
            st.error("""
            ‚ö†Ô∏è **PyPortfolioOpt is not installed!**
            
            Some optimization features will be limited. Install with:
            ```bash
            pip install PyPortfolioOpt
            ```
            """)
        
        if not QUANTSTATS_AVAILABLE:
            st.warning("""
            ‚ö†Ô∏è **quantstats is not installed!**
            
            Some advanced performance metrics will be limited. Install with:
            ```bash
            pip install quantstats
            ```
            """)
        
        # Run the main application
        main()
        
    except Exception as e:
        st.error(f"Application Error: {str(e)}")
        st.error(traceback.format_exc())
        
        # Provide recovery options
        st.markdown("""
        ### üîß Recovery Options:
        
        1. **Clear cache and restart** - Click the "Clear Cache" button in the sidebar
        2. **Check your internet connection** - The app needs to download market data
        3. **Reduce the number of assets** - Try with fewer assets first
        4. **Check the console for detailed error messages**
        
        If the problem persists, please report the issue with the error details above.
        """)
